To run a locally hosted dashboard in my browser I can run:
minikube dashboard --port=63840 (Port can be any port specified)

------------------

A Pod is the smallest and simplest unit in the Kubernetes object model that you create or deploy. It represents one (or sometimes more) running container(s) in a cluster. 
In a simple web application, you might have one single pod: the web server. As traffic grows, you might deploy that same code to multiple pods to handle the increased load. Several pods, one codebase. 
In a more complex backend system, you might have several pods for the web server and several pods that handle video processing. Multiple pods, multiple codebases.

Pod Illustration

Pods are just wrappers around containers. You can think of it as a Docker container with a little extra Kubernetes magic. The container is the actual application, 
and the Pod is the Kubernetes abstraction that manages the container and the resources it needs to run.

------------------

First, download a copy of your deployment's YAML file and save it in your current directory:

kubectl get deployment synergychat-web -o yaml > web-deployment.yaml

Then open it in your text editor. There are 5 top-level fields in the file:

- apiVersion: apps/v1 - Specifies the version of the Kubernetes API you're using to create the object (e.g., apps/v1 for Deployments).
- kind: Deployment - Specifies the type of object you're configuring
- metadata - Metadata about the deployment, like when it was created, its name, and its ID
- spec - The desired state of the deployment. Most impactful edits, like how many replicas you want, will be made here.
- status - The current state of the deployment. You won't edit this directly, it's just for you to see what's going on with your deployment.
- Inside your editor, change the number of replicas to 3 and save the file. Notice that you're just editing a file on your machine! It won't yet have any effect on the deployment in your cluster.

To apply the changes, run:

kubectl apply -f web-deployment.yaml

You should get a warning that lets you know that you're missing the last-applied-configuration annotation. That's okay! we got that warning because we created this deployment the quick and dirty way, 
by using kubectl create deployment instead of creating a YAML file and using kubectl apply -f.

However, because we've now updated it with kubectl apply, the annotation is now there, and we won't get the warning again.

-------------------

Create a deployment file then run: 

kubectl apply -f <deployment yaml filename>

-------------------

- Thrashing Pods
One of the most common problems you'll run into when working with Kubernetes is Pods that keep crashing and restarting. This is called "thrashing" and it's usually caused by one of a few things:

The application recently had a bug introduced in the latest image version
The application is misconfigured and can't start properly
A dependency of the application is misconfigured and the application can't start properly
The application is trying to use too much memory and is being killed by Kubernetes

- What Is “CrashLoopBackoff”?
When a pod's status is CrashLoopBackoff, that means the container is crashing (the program is exiting with error code 1).

Because Kubernetes is all about building self-healing systems, it will automatically restart the container. However, each time it tries to restart the container, if it crashes again, it will wait longer and longer in between restarts. That's why it's called a "backoff".

To fix a thrashing pod, you need to find out why it's crashing.

-------------------

Get kist of pods: 
kubectl get pods

Get the logs for a specified pod:
kubectl logs <pod-name>

-------------------

When making changes to a .yaml file always apply changes:

kubectl apply -f <.yaml file> 

** with config maps it doesnt apply to the pod, it just creates and stores the config map in k8.

Real organizations store their Kubernetes configurations (like your ConfigMap) in YAML files and keep them in version control (like Git). This means:

Changes can be tracked
Multiple team members can review changes
You can roll back to previous versions if needed
Repeatability: Using YAML files means you can:

Set up the same environment in development, staging, and production
Quickly recover if something goes wrong
Share configurations with team members
GitOps: Many organizations use GitOps practices where:

All changes to infrastructure are made through git
CI/CD pipelines automatically run kubectl apply -f when changes are merged

------------------------

- Applying the Config Map

Open up your api-deployment.yaml file. We're going to add a few things to it. Under the containers section, add the following to the first (and only) entry:

env:
  - name: API_PORT
    valueFrom:
      configMapKeyRef:
        name: synergychat-api-configmap
        key: API_PORT

This tells Kubernetes to set the API_PORT environment variable to the value of the API_PORT key in the synergychat-api-configmap config map. Reference the official docs if you're confused about the structure of the yaml.

Next, apply the deployment. Hopefully, you remember the command for this by now.

Once it's applied, you should be able to take a look at the pods and see that a new API pod has been deployed and isn't crashing!

Let's forward the API pod's 8080 port to our local machine so we can test it out.

kubectl port-forward <pod-name> 8080:8080

Make sure it returns a 404 response when you hit the root:

curl http://localhost:8080

-------------------------

Config Maps Are Insecure
ConfigMaps are a great way to manage innocent environment variables in Kubernetes. Things like:

Ports
URLs of other services
Feature flags
Settings that change between environments, like DEBUG mode
However, they are not cryptographically secure. ConfigMaps aren't encrypted, and they can be accessed by anyone with access to the cluster.

If you need to store sensitive information, you should use Kubernetes Secrets or a third-party solution.

-------------------------

We can use the envFrom key instead of the env key to reference the entire config map and make it available to the pods in the deployment:

instead of this:

spec:
  replicas: 1
  selector:
    matchLabels:
      app: synergychat-api
  template:
    metadata:
      labels:
        app: synergychat-api
    spec:
      containers:
      - name: synergychat-api
        image: bootdotdev/synergychat-api:latest
        env: # reference from here down #
          - name: API_PORT
            valueFrom:
              configMapKeyRef: 
                name: synergychat-api-configmap
                key: API_PORT
          - name: THING_TWO
            valueFrom:
              configMapKeyRef:
                name: synergychat-api-congigmap
                key: THING_TWO
          - name: THING_THREE
            ...

we can use envFrom:

spec:
  replicas: 1
  selector:
    matchLabels:
      app: synergychat-crawler
  template:
    metadata:
      labels:
        app: synergychat-crawler
    spec:
      containers:
      - name: synergychat-crawler
        image: bootdotdev/synergychat-crawler:latest
        envFrom:
          - configMapRef:
              name: synergychat-crawler-configmap

----------------------

Services
We've spun up pods and connected to them individually, but that's frankly not super useful if we want to distribute real traffic across those pods. That's where services come in.

Services provide a stable endpoint for pods. They are an abstraction used to provide a stable endpoint and load balance traffic across a group of Pods. By "stable endpoint", 
I just mean that the service will always be available at a given URL, even if the pod is destroyed and recreated.

Create a file called web-service.yaml and add the following:

apiVersion: v1
kind: Service
metadata/name: web-service (we could call it anything, but this is a fine name)
spec/selector/app: I'm going to let you figure out what should be here. This is how the service knows which pods to route traffic to.
spec/ports: An array of port objects. You need one entry:
protocol: TCP (TCP will allow us to use HTTP)
port: 80 (this is the port that the service will listen on)
targetPort: 8080 (this is the port that the pods are listening on)
This creates a new service called web-service with a few properties:

It listens on port 80 for incoming traffic
It forwards that traffic to pods that are listening on their port 8080
Its controller will continuously scan for pods matching the app: synergychat-web label selector and automatically add them to its pool


Now, let's forward the service's port to our local machine so we can test it out.

kubectl port-forward service/web-service 8080:80

----------------------

Service Types
Take a look at the yaml that describes your web-service.

kubectl get svc web-service -o yaml

"svc" is a short-hand alias for "service", either will work in kubectl.

You should see a section that looks like this:

spec:
  clusterIP: 10.96.213.234
  ...
  type: ClusterIP

We didn't specify a service type! Why is this here? Well, it's because ClusterIP is the default service type.

The clusterIP is the IP address that the service is bound to on the internal Kubernetes network. Remember how we talked about how pods get their own internal, 
virtual IP address? Well, services can too! However, type: ClusterIP is just one type of service! There are several others, including:

- NodePort: Exposes the Service on each Node's IP at a static port.

- LoadBalancer: Creates an external load balancer in the current cloud environment (if supported, e.g. AWS, GCP, Azure) and assigns a fixed, external IP to the service.

- ExternalName: Maps the Service to the contents of the externalName field (for example, to the hostname api.foo.bar.example). 

The mapping configures your cluster's DNS server to return a CNAME record with that external hostname value. No proxying of any kind is set up.
The interesting thing about service types is that they typically build on top of each other. For example, 
a NodePort service is just a ClusterIP service with the added functionality of exposing the service on each node's IP at a static port (it still has an internal cluster IP).

A LoadBalancer service is just a NodePort service with the added functionality of creating an external load balancer in the current cloud environment (it still has an internal cluster IP and node port).

An ExternalName service is actually a bit different. All it does is a DNS-level redirect. You can use it to redirect traffic from one service to another.

-------------------------

When a request comes in:

Web service receives user request
Web service calls api-service using its internal DNS name (like api-service.default.svc.cluster.local)
API service processes request, maybe calls crawler-service for data
Data flows back up the chain

Why Separate These Components?:
Scalability: Each component can scale independently
Isolation: If crawler fails, web and API might still work
Maintenance: Can update one component without touching others

Service Discovery:
Kubernetes automatically creates internal DNS entries
Services find each other using consistent names
If a pod dies, service redirects traffic to healthy pods

--------------------

DNS
Now that we've configured the ingress to route the domains:

synchat.internal to the web-service
synchatapi.internal to the api-service
We need to configure our local machine to resolve those domains to the ingress load balancer. We won't be setting up global DNS so that anyone on the internet can access our app! 
We'll just be configuring our local machine to resolve those domains to the ingress load balancer.

To resolve hostnames to IP addresses locally you can edit /etc/hosts file as an administrator in both WSL and PowerShell

I added these lines:

127.0.0.1 synchat.internal
127.0.0.1 synchatapi.internal

to PowerShell: notepad C:\Windows\System32\drivers\etc\hosts

to WSL: vim /etc/hosts

---------------------


Great question! The "network resolution process" refers to how a request travels from your browser to the actual Kubernetes pod running your application.

Let's break down the steps in order:

- DNS (/etc/hosts): When you type synchat.internal in your browser, your computer needs to figure out what IP address that domain points to. It checks your /etc/hosts file (which we modified earlier) 
  and finds that it points to 127.0.0.1.

- IP address: Now your browser knows to send the request to 127.0.0.1 (localhost), which is where the minikube tunnel is listening.

- Ingress controller: The request reaches the ingress controller (like NGINX) running in your Kubernetes cluster. The ingress controller looks at the host header (synchat.internal) 
  and path to determine which service should receive this request.

- Service: The ingress routes your request to the appropriate Kubernetes service, which acts as a stable internal address and load balancer for your pods.

- Pod: Finally, the service forwards the request to one of the available pods running your application.

---------------------

In production, the process would look more like this:

- DNS (real DNS servers): When users type your domain (like example.com), their request goes to real DNS servers on the internet, which resolve to your cloud provider's load balancer IP address.

- IP address: Traffic reaches your cloud provider's load balancer IP.

- Ingress controller: The load balancer forwards traffic to your Kubernetes ingress controller.

- Service: The ingress routes to the appropriate service.

- Pod: The service routes to a pod.

--- The localhost and /etc/hosts approach we're using is just a development convenience that mimics production while letting you work locally. In production, you'd:

- Register a real domain name
- Configure DNS to point to your cloud load balancer
- Set up TLS certificates for HTTPS

---------------------

DNS stands for Domain Name System. It's essentially the internet's phone book that translates human-friendly domain names (like google.com) into IP addresses (like 142.250.190.78) 
that computers use to identify each other.

TLS stands for Transport Layer Security. It's a cryptographic protocol that provides secure communication over a computer network. When you see HTTPS instead of HTTP in your browser, 
that "S" means the connection is secured with TLS. This ensures that data exchanged between your browser and the website is encrypted and can't be easily intercepted or tampered with.

---------------------

- Ingress Types
You may have noticed that at the top of all our resources we have this in the yaml:

apiVersion: v1

This is the API version of the resource, and because those resources are core to Kubernetes, they're in the standard v1 API group.

However, ingress isn't a core Kubernetes resource, it's an extension of sorts. That's why it has:

apiVersion: networking.k8s.io/v1

You can think of the networking.k8s.io API group as a core extension. It's not third-party (it's on k8s.io for heaven's sake), but it's not part of the core Kubernetes API either.

-----------------------

Annotations
You probably noticed that we used a single annotation on our ingress resource:

  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /

This is a really common pattern in Kubernetes. The core Kubernetes API is intentionally kept small, but there are a lot of things that people want to do with Kubernetes that aren't part of the core API. 
So, instead of adding a bunch of new fields to the core API, Kubernetes allows you to add arbitrary annotations to your resources, and then various extensions can read those annotations and do things with them.

For example, the Boot.dev Kubernetes cluster uses an ingress extension specific to Google Cloud Platform. We use the following annotations so that our controller knows which static IP address to use, 
which SSL certificate to use, and how to route traffic to our ingress:

  annotations:
    kubernetes.io/ingress.global-static-ip-name: static-ip-name-here
    networking.gke.io/managed-certificates: cert-name-here
    kubernetes.io/ingress.class: gce

If you're curious about the specifics, the docs are here. In a nutshell, however, the important take-away is that in most production deployments you'll be using annotations specific to the cloud provider you're using. 
Each major cloud provider has their own products, so you need to use k8s annotations and extensions specific to that cloud provider.

Now that you understand the basic concepts of ingress, in the future, it's just a matter of following the documentation for your cloud provider to get it set up.


When you see https instead of http it means your using TLS which a security protocol that created an encrypted connection between the web server and the browser.
SSL = Secure Sockets Layer
TLS = Transport Layer Security

-------------------------

Ephemeral Volumes
On-disk files in a container are ephemeral as we saw in the last lesson. This presents some problems for applications that want to save long-lived data across restarts. For example, user data in a database.

The Kubernetes volume abstraction solves two primary problems:

Data persistence
Data sharing across containers
As it turns out, there are a lot of different types of "volumes" in Kubernetes. Some are even ephemeral as well, just like a container's standard filesystem. 
The primary reason for using an ephemeral volume is to share data between containers in a pod.

Add a volumes section to spec/template/spec.
volumes:
  - name: cache-volume
    emptyDir: {}

Add a new volumeMounts section to the container entry. This will mount the volume we just created at the /cache path.
volumeMounts:
  - name: cache-volume
    mountPath: /cache

Duplicate the entire first entry in the containers list twice (you should now have 3 total containers). Update the name of each:
synergychat-crawler-1
synergychat-crawler-2
synergychat-crawler-3
Now all the containers in the pod will share the same volume at /cache. It's just an empty directory, but the crawler will use it to store its data.

Add a CRAWLER_DB_PATH environment variable to the crawler's ConfigMap. Set it to /cache/db. The crawler will use a directory called db inside the volume to store its data.
Apply the new ConfigMap and Deployment, and use kubectl get pod to see the status of your new pod.
You should notice that there's a problem with the pod! Only 1/3 of containers should be "ready". Use the logs command to get the logs for all 3 containers:

kubectl logs <podname> --all-containers

You should see something like this:

listen tcp :8080: bind: address already in use

Because pods share the same network namespace, they can't all bind to the same port! Hmm... let's put a bandaid on this by binding each container to a different port. 8080 is the only one that will 
be exposed via the service, but that's okay for now. We can add redundancy later.

Add two new values to the crawler's ConfigMap:

CRAWLER_PORT_2: 8081

CRAWLER_PORT_3: 8082

Update the crawler deployment:

Change the second and third containers to map CRAWLER_PORT_2 -> CRAWLER_PORT and CRAWLER_PORT_3 -> CRAWLER_PORT respectively (the Docker image expects a variable named "CRAWLER_PORT"). 
I'm not going to give you the code, but know that it's gonna be a bit tedious because you need to use 
env: instead of envFrom: for the second and third containers. Don't forget to continue exposing the CRAWLER_KEYWORDS and CRAWLER_DB_PATH environment variables for all containers.

-------------------------

-- Persistence

All the volumes we've worked with so far have been ephemeral, meaning when the associated pod is deleted the volume is deleted as well. This is fine for some use cases, 
but for most CRUD apps we want to persist data even if the pod is deleted.

If you think about it, it's not even just when pods are explicitly deleted with kubectl that we need to worry about data loss. Pods can be deleted for several reasons:

The node they're running on could fail
A new version of the image was published (code was updated, etc)
A new node was added to the cluster and the pod was rescheduled
In all of these cases, we want to make sure that our data is still available. Persistent volumes allow us to do this.

-- Persistent Volumes (PV)
Instead of simply adding a volume to a deployment, a persistent volume is a cluster-level resource that is created separately from the pod and then attached to the pod. It's similar to a ConfigMap in that way.

PVs can be created statically or dynamically.

Static PVs are created manually by a cluster admin
Dynamic PVs are created automatically when a pod requests a volume that doesn't exist yet
Generally speaking, and especially in the cloud-native world, we want to use dynamic PVs. It's less work and more flexible.

-- Persistent Volume Claims (PVC)
A persistent volume claim is a request for a persistent volume. When using dynamic provisioning, a PVC will automatically create a PV if one doesn't exist that matches the claim.

The PVC is then attached to a pod, just like a volume would be.

-- Assignment
Create a new file called api-pvc.yaml and add the following:

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: xxx
spec:
  accessModes:
    - xxx
  resources:
    requests:
      storage: xxx

-- Add the following properties:

metadata/name: synergychat-api-pvc
spec/accessModes: An array with one entry:
ReadWriteOnce
spec/resources/requests/storage: 1Gi
This creates a new PVC called synergychat-api-pvc with a few properties that can be read from and written to by multiple pods at the same time. It also requests 1GB of storage.

Apply the PVC.

kubectl apply -f api-pvc.yaml

Run both of these commands:

kubectl get pvc
kubectl get pv

You should see that a new PV was created automatically!

-------------------------

-- Attach Persistence
So far all we've done is create an empty persistent volume. Let's get the api application to use it.

Assignment
Use your crawler deployment and the docs as a reference. Create a new volume in the api-deployment referencing your pvc:

volumes:
  - name: synergychat-api-volume
    persistentVolumeClaim:
      claimName: synergychat-api-pvc

Then mount it in the container under the /persist directory:

volumeMounts:
  - name: synergychat-api-volume
    mountPath: /persist

Update the API_DB_FILEPATH environment variable you added earlier to instead use the new mount path: /persist/db.json

Apply the changes, then check to make sure all your pods are healthy:

kubectl get pods

With your tunnel running (minikube tunnel -c), open http://synchat.internal/ in your browser.

Send some messages.
Delete the api pod.
Once the new pod is running, refresh the page and make sure your messages are still there. If they are, your persistent volume is working!

-------------------------

-- Databases
Now that you know all about volumes, you might be thinking, "Awesome! I'll host my CRUD app on Kubernetes and use a volume to store my PostgreSQL database data!".

That's certainly possible, but frankly, it's not always the best idea. For example, the Boot.dev system that powers this website has the following components:

A web application, currently served by Cloudflare (this could easily be a Kubernetes deployment if we cared to move it)
Several backend microservices, all running on Kubernetes in Google Cloud
Our main JSON CRUD API
A Discord bot
A service that compiles student's Go code to WASM
etc
A managed PostgreSQL database, hosted by Cloud SQL (GCP)
Why do we do this? Well, Kubernetes isn't always the simplest way to get a job done. We could certainly host a PostgreSQL database on Kubernetes, but it would require a lot of extra work to get it to work well. 
For example, we'd need to manually build all the configurations to:

-- Create a persistent volume
Handle Postgres version updates
Set resource limits
Set up automated backups
For that reason, when I need an SQL database, I typically use a managed service like Cloud SQL or RDS. There are exceptions to that rule, but it's a good rule of thumb.

-- When Would You Use a Database on Kubernetes?
I have used databases on Kubernetes in the past, but I've usually done it when the deployment wasn't exactly mission-critical. For example, I've deployed Grafana and Prometheus on Kubernetes, 
and they both have out-of-the-box support for in-cluster databases. I didn't care too much about backups and automatic upgrades for my telemetry data, and I knew the data set was small and static, so it was a good fit

-------------------------

Namespaces
To quote the Zen of Python:

Namespaces are one honking great idea -- let's do more of those!

Namespaces are a way to isolate cluster resources into groups. They're a bit like directories on your computer, but instead of containing files, they contain Kubernetes objects. 
As you've already learned, every resource in Kubernetes has a name. Some of our names include:

synergychat-api-configmap
api-service
api-deployment
web-deployment
...
You can only use a name once. It is a unique identifier. That's how kubectl apply knows when it should create a new resource and when it should update an existing one. 
Namespaces allow us to use the same name for different resources, as long as they're in different namespaces.

Run the following command:

kubectl get namespaces

or the shorter version:

kubectl get ns

-------------------------

-- Moving Namespaces

Up until this point, we've been working in the default namespace. When using kubectl commands, you can specify the namespace with the --namespace or -n flag. 
If you don't, it will use the default namespace.

The kube-system namespace is where all the core Kubernetes components live, it's created automatically when you install Kubernetes. You don't want to mess with it.

Making a New Namespace
If you have a small cluster with only a few applications, you can probably get away with just using the default namespace. However, if you have a large cluster with many applications, 
and in particular many teams working on those applications, namespaces are a great way to keep things organized.

For the sake of learning, let's assume that we have a separate development team responsible for the crawler service at SynergyChat, and they want to have their own namespace.

Create a new namespace: 
kubcetl create ns <namespace name>

Verify it was created: 
kubectl get ns

After creating a new namspace you have to add the namespace to the metadata section of all files you want moved to the namespace.

Verfiy the resources are now redeployed in the new namespace:
kubectl -n <namespace name> get pods
kubectl -n <namespace name> get svc
kubectl -n <namespace name> get configmaps

then delete the old resources in the default namespace: 
kubectl delete deployment <deployment name>
kubectl delete service <service name>
kubectl delete configmap <configmap name>

-------------------------

-- Intra-Cluster DNS

Intra-Cluster DNS
The front-end of SynergyChat communicates with the api application via an external ingress:

Domain name http://synchatapi.internal -> ingress -> service -> pod

It's now time to connect the crawler and api applications. The api needs to be able to make HTTP requests directly to the crawler so that it can get the latest data to power the "stats" slash command.

front-end -> api -> crawler

The HTTP communication between the api and crawler is strictly internal to the cluster, there's no need for an external domain name or ingress. That makes it simpler, faster and more secure.

-- Slash Command
With the tunnel open (minikube tunnel -c) open http://synchat.internal/ in your browser. Post a new message with /stats as the message text. You should see a response that says:

crawler-bot: Crawler worker not configured

That's because the api doesn't know how to communicate with the crawler yet. Let's fix that.

-- DNS
Kubernetes automatically creates DNS entries for each service that can be used to route HTTP traffic between services. The format is:

<service-name>.<namespace>.svc.cluster.local

-- Assignment
Update the api application's ConfigMap and Deployment to add a new environment variable called CRAWLER_BASE_URL its value should be:

http://<service-name>.<namespace>.svc.cluster.local

Replace <service-name> and <namespace> with the appropriate values for the crawler service. This will allow the api to make HTTP requests to the crawler service.

Apply your changes, restart the pod, then post a new message to SynergyChat with /stats as the message text and answer the question on the right.

-- Tip
If it's not connecting, you may need to include the port:

http://<service-name>.<namespace>.svc.cluster.local:8080

-------------------------

-- Namespace and Routing Review
Namespaces are used to separate resources into logical groups. They also impact how internal DNS works.

At Boot.dev, we have all of our production backend services in a namespace, let's pretend it's called "backend". Each time I use kubectl to work with the backend services, I have to specify the namespace:

kubectl -n backend get pods

-- Internal Routing
Kubernetes makes it really easy for pods to communicate with each other. It does this by automatically creating DNS entries for each service. The format is:

<service-name>.<namespace>.svc.cluster.local

In reality, the .svc.cluster.local isn't needed in most scenarios. If you just use http://<service-name>.<namespace> for the api->crawler communication, it will work. When working in the same namespace, 
you can even just use http://<service-name>. That wouldn't work for us in our scenario just because the crawler is in its own separate namespace.

-- Internal Is Better Than External
Unless a service really needs to be made available to the outside world, it's better to keep it internal to the cluster. Internal communications are great because:

- It's faster (assuming nodes are close to each other physically)
- No public DNS is required
- Communication is inherently more secure because it runs on an internal network (usually don't even need HTTPS)

-- The architecture of SynergyChat is a good example of this. 
*** We expose a single JSON API to the outside world, and if the pod that serves those HTTP requests doesn't have all the info it needs locally, 
it makes internal HTTP requests to other services.*** 

-------------------------

-- Vertical and Horizontal Scaling
Generally speaking, there are two ways to scale an application: vertically and horizontally. When I say "Scaling", I'm talking about increasing the capacity of an application. 
For example, maybe we have a web server, and to handle roughly 1000 requests per second, it uses about:

1/2 of a CPU core
1 GB of RAM
If we want to "scale up" to handle 2000 requests per second, we could double the CPU and RAM:

1 CPU core
2 GB of RAM
This is called "vertical scaling" because we're increasing the capacity of the application by increasing the resources available to it. We're scaling up. Scaling up works until it doesn't. 
You can only scale up as much as your hardware will allow (the maximum number of CPUs and amount of RAM your node has).

The other way to scale is horizontally. Instead of increasing the resources available to the application, we increase the number of instances of the application (pods). 
Pods can be distributed across nodes, so we can scale horizontally until we run out of nodes. When working in a system like Kubernetes, it's generally better to scale horizontally than vertically.

-------------------------

-- Resource Limits
None of our current deployments have any resource limits set. We have very little traffic, so it's not currently an issue, but in a production environment, we would want to set resource limits to ensure that our pods don't consume too many resources.

We wouldn't want a pod to hog all the CPU and RAM on its node, suffocating all of the other pods on the node.

-- Setting Limits
We can set resource limits in our deployment files. Here's an example:

spec:
  containers:
  - name: <container-name>
    image: <image-name>
    resources:
      limits:
        memory: <max-memory>
        cpu: <max-cpu>

Memory is measured in bytes, so we can use the suffixes Ki, Mi, and Gi to specify kilobytes, megabytes, and gigabytes, respectively. For example, 512Mi is 512 mebibytes.

CPU is measured in cores, so we can use the suffix m to specify milli-cores. For example, 500m is 500 milli-cores, or 0.5 cores.

The bootdotdev/synergychat-testcpu:latest image on Docker Hub is an application that simply consumes as much CPU power as it can.

Create a new file called testcpu-deployment.yaml with the following:

Add a CPU limit of 50m to the deployment.

Apply the deployment, then make sure the pod is running:

kubectl get pod

It might take a minute or so, but soon you should be able to see its metrics with top:

kubectl top pod

-------------------------

-- Limits - RAM
We've successfully throttled the CPU usage of our testcpu pod, but what about RAM?

Create a new file called testram-deployment.yaml with the following:

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: synergychat-testram
  name: synergychat-testram
spec:
  replicas: 1
  selector:
    matchLabels:
      app: synergychat-testram
  template:
    metadata:
      labels:
        app: synergychat-testram
    spec:
      containers:
        - image: bootdotdev/synergychat-testram:latest
          name: synergychat-testram

Add a memory limit of 256Mi (256 Megabytes) to the deployment. Remember, this is the syntax to do so:

spec:
  containers:
  - name: <container-name>
    image: <image-name>
    resources:
      limits:
        memory: <max-memory>
        cpu: <max-cpu>

Additionally, create a ConfigMap called testram-configmap.yaml with the name "synergychat-testram-configmap" for this deployment that specifies a single environment variable:

MEGABYTES: "200"
That will tell the application to allocate 200 megabytes of memory. Update the deployment to use the config map, then apply both.

Make sure the pod is healthy:

kubectl get pods

After a minute or so, you should be able to see the memory usage of the pod:

kubectl top pods

The memory usage should be a little over 200 megabytes, but not more than 256 megabytes.

-------------------------

-- Nodes
We've talked about how in a production environment, you'll have multiple nodes in your cluster. For this course, we've been using a single node cluster with minikube. The nice thing about Kubernetes is that almost everything you do with it is abstracted away from the underlying infrastructure with the kubectl CLI.

All the commands we've been using locally will work the same way on a production cluster.

Ways to Deploy to Production
There are several popular ways to deploy a Kubernetes cluster to production:

GKE (Google Kubernetes Engine) / Autopilot
EKS (Amazon Elastic Kubernetes Service)
AKS (Azure Kubernetes Service)
Manual Deployment

Gke, Eks, Aks
These are all managed Kubernetes services, offered by the big 3 cloud providers. They're all pretty similar, though I believe GKE is generally the most feature-rich of the three. 
GKE also has a cool auto-pilot mode that makes it so that you don't have to worry about managing nodes at all.

The nice thing about a managed offering is that it can be configured to handle autoscaling at the node level. This means that you can set up your cluster to automatically 
add and remove nodes based on the load of your cluster.

Manual
You can also set up your own cluster manually. I've worked on teams where a cloud engineering team has custom scripts that configure a cluster on top of standard EC2 instances. 
Then they have their own autoscaling scripts that add and remove nodes based on the load of the cluster. I happened to work at a company that manually deployed k8s to a group of AWS virtual machines, 
but you could also do the same thing on physical machines.

Deploying manually was more popular before the managed services were released, but it's still a viable option if you want more control over your cluster.

-------------------------

Node Types
Broadly speaking, there are two types of machines in a production Kubernetes cluster:

Control Plane
Worker Nodes
node diagram

The control plane is responsible for managing the cluster. It's where the API server, scheduler, and controller manager live. The control plane used to be called "master nodes", but that term is deprecated now.

When you hear the word "node" used in isolation it's usually referring to worker nodes. In fact, because I'm using GKE for Boot.dev, when I run:

kubectl get nodes

I get back:

NAME                                       STATUS   ROLES    AGE     VERSION
gk3-kube-prod-nap-1cmjprlt-92e1dc91-jmi8   Ready    <none>   5d21h   v1.25.12-gke.500
gk3-kube-prod-nap-1cmjprlt-dfe4d6de-cq0k   Ready    <none>   5d21h   v1.25.12-gke.500

These are my worker nodes. They're the machines that are actually running my containers. The control plane is fully managed by GKE, so I don't have to worry about it. 
That's usually fine because as the load on my cluster increases, I'm mostly concerned with scaling out my worker nodes and making sure they're healthy. The control plane is fairly static.

-- If I want to run many more pods, which type of node would I likely need more of?
    Worker nodes

-- Which nodes are typically handled by the cloud provider in a managed Kubernetes cluster?
    Control plane

-------------------------

-- Resource Requests
We talked about resource limits, but there's another critical concept to understand: resource requests.

A resource request is the amount of a resource that a pod requests from the node it's running on. 
A resource limit, on the other hand, is the maximum amount of a resource that a pod is allowed to consume before it's throttled or killed.

Let's say we have 2 nodes:

Node	  RAM
Node 1	8GB
Node 2	8GB

And we have 4 pods:

Pod	  Node	  RAM
Pod 1	Node 1	3GB
Pod 2	Node 1	3GB
Pod 3	Node 2	3GB
Pod 4	Node 2	3GB
This is valid. Currently, only 6/8 GB of RAM is being used on each node. The trouble is, even though each node has 2GB of RAM left, if we try to add another pod, 
and it ends up utilizing more than 2GB of RAM (like the 3GB it will likely need), it will crash.

Resource requests solve this.

If we add a resource request of 3GB, Kubernetes will know that each pod needs 3GB of RAM to run. If we try to schedule a new pod with the request in place, k8s will 
gracefully tell us it doesn't have enough resources to do so, or it will use a node in the cluster that has at least 3GB of RAM available.

Update the resources section of its deployment. I used 40GB:
resources:
  limits:
    memory: 40000Mi
  requests:
    memory: 40000Mi

apply the deployment and check on pods: 
kubectl get pods

Once you've got it in a pending state, describe the pod and look at the "Events" section of the output to see what's going on:
kubectl describe pod <pod-name>

-------------------------

-- Requests
One of the most important things to get right when working with pod autoscalers in Kubernetes are the resource requests and limits. If you don't set them correctly, you can end up with a situation where your pods are crashing, or your autoscaler is scaling up too many pods.

Generally speaking, my rule of thumb is:

- Set memory requests ~10% higher than the average memory usage of your pods
- Set CPU requests to 50% of the average CPU usage of your pods
- Set memory limits ~100% higher than the average memory usage of your pods
- Set CPU limits ~100% higher than the average CPU usage of your pods

--Why these numbers? Consider several points:

-- Memory Is Scarier
Memory is the scariest resource to run out of. If you run out of CPU, your pods will just slow down. If you run out of memory, your pods will crash. For that reason, 
it's more important to add a buffer to your memory requests than your CPU requests.

-- Limits Are for Protection
Limits should only take effect when a pod is using more resources than it should. Limits are like a safety net. If your limits are constantly being hit, 
you should either increase them or fix your application code so that it uses fewer resources.

As such, limits should generally be set higher than requests.

-- Requests Are for Scheduling
Because requests are used to schedule pods, you want to make sure that your requests are high enough that once scheduled, your pods will have the resources, 
but not so high that you're wasting resources. If you set your requests too high, you'll end up with a situation where you can't schedule pods because k8s thinks it doesn't have enough resources, 
even though it does.

-- It All Depends!
These are just rules of thumb! At the end of the day, you always need to understand how your applications work, and what resources they need. 
The right numbers for your applications might be drastically different than the numbers I've suggested here.

-------------------------

Global Notes:

Use this to restart a deployment after updating and appying a config map:
kubectl rollout restart deployment <deployment name> Use <kubectl get deployment> to get deployment name. 

minikube tunnel -c
minikube dashboard --port=63840

Kubernetes is an orchestration system that manages containerized applications, typically running in Docker containers (though it can work with other container runtimes too).

In this scenario:

You have multiple pods running in your Kubernetes cluster
Each pod contains one or more containers (which are typically Docker containers)
The containers run your actual application code
So rather than everything running in one Docker container, it's:

Multiple Docker containers
Grouped into pods (some pods have 1 container, the crawler pod has 3)
All managed by Kubernetes
This is more like a nested structure:

Kubernetes cluster contains many pods
Pods contain one or more containers
Containers run your applications

-- General rule of thumb: 
All HTTP servers should have a(n) service resource but should only have a(n) ingress resource if they need to be exposed to clients outside the cluster.

----------------------------